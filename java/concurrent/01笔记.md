# 并发编程的核心：
1. 分工：如何高效地拆解任务并分配给线程
2. 同步：线程之间如何协作：当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行。
   1. 管程：解决并发问题的关键
3. 互斥：同一时刻只允许一个线程访问共享资源

# 多线程导致结果不确定的主要问题（内存模型）
- 可见性问题
- 有序性问题
- 原子性问题

> ReadWriteLock、StampedLock：优化读多写少场景下锁的性能
> 无锁的数据结构：原子类
> 不共享变量或者变量只允许读：Thread Local和final关键字，Copy-on-write的模式

![并发知识点](img/并发全貌.png)

为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：
1. CPU 增加了缓存，以均衡与内存的速度差异；
2. 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
3. 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用

可见性：一个线程对共享变量的修改，另一个线程能够立刻看到。

> 操作系统做任务切换，可以发生在任何一条CPU指令执行完。

原子性：一个或者多个操作在CPU执行的过程中不被终端的特性

有序性：程序按照代码的先后顺序执行。
```java
//编译器优化带来的bug
public class Singleton {
   static Singleton instance;
   static Singleton getInstance(){
      if (instance == null) {
         synchronized(Singleton.class) {
            if (instance == null)
               instance = new Singleton();
         }
      }
      return instance;
   }
}
// 常规理解：线程A，B同时调用**getInstance()**方法，在第一个判断过后两线程同时对**Singleton.class**加锁，而`JVM`保证只有一个线程加锁成功，另一个线程会处于等待状态, 
// 当第一个线程获得锁并创建对象成功后，第一个线程释放锁，第二个线程取得锁后进行判断，发现对象已创建，结束逻辑，释放锁。

// 可能出问题的点在`new`
// 常认为`new`操作为：
// 1. 分配一块内存 M
// 2. 在内存 M 上初始化 Singleton 对象
// 3. 然后 M 的地址赋值给 instance 变量

// 实际上`new`操作为：
// 1. 分配一块内存 M
// 2. 然后 M 的地址赋值给 instance 变量
// 3. 在内存 M 上初始化 Singleton 对象
```
> 导致的结果
> ![双重检查创建单例的一场执行路径.png](img/双重检查创建单例的一场执行路径.png)

--- 
> 缓存导致的可见性问题
> 线程切换带来的原子性问题
> 编译优化带来的有序性问题

---
解决可见性、有序性最直接的办法：禁用缓存和编译优化
Java内存模型规范了JVM如何提供按需禁用缓存和编译优化的方法。
三个关键字：`volatile`、`synchronized`、`final`
六项`Happens-Before`原则

---
- volatile：告诉编译器，对于变量的读写，不能使用CPU缓存，必须从内存中读取或写入
- Happens-Before：前面一个操作的结果对后续操作是可见的
---
- Happens-Before
1. 程序的顺序性规则：一个线程中，按照程序顺序，前面的操作Happens-Before于后续的任意操作，程序前面对某个变量的修改一定是对后续操作可见的。
> 代码按程序顺序
```java
class VolatileExample {
 int x = 0;
 volatile boolean v = false;
 public void writer() {
 x = 42; // x=42 happens before v =true
 v = true; 
 }
 public void reader() {
 if (v == true) {
 }
 }
}
```
2. volatile变量规则：对一个volatile变量的写操作，Happens-Before于后续对这个volatile变量的读操作。
```java
class VolatileExample {
 int x = 0;
 volatile boolean v = false;
 public void writer() {
 x = 42; 
 v = true; 
 }
 public void reader() {
 if (v == true) {
    System.out.println(x); //x=42 这里的读操作 在写操作之后
 }
 }
}
```
3. 传递性：如果A Happens-Before B，且B Happens-Before C，那么A Happens-Before C。
```java
class VolatileExample {
 int x = 0;
 volatile boolean v = false;
 public void writer() {
 x = 42; 
 v = true; 
 }
 public void reader() {
 if (v == true) {
    System.out.println(x); //x=42 先writer()，后reader()，x写->v写->v读，传递依赖
 }
 }
}
```
4. 管程中锁的规则：对一个锁的解锁 Happens-Before于后续对这个锁的加锁
```
synchronized (this) { // 加锁
 // x 是共享变量, 初始值 =10
 if (this.x < 12) {
 this.x = 12;
 }
} // 解锁
// 解锁的指令在加锁指令后
```
5. 线程start()规则：主线程A启动子线程B后，子线程B能够看到主线程在启动子线程B前的操作
```
Thread B = new Thread(()->{
 // 主线程调用 B.start() 之前
 // 所有对共享变量的修改，此处皆可见
 // 此例中，var==77
});
// 此处对共享变量 var 修改
var = 77;
// 主线程启动子线程
B.start();
```
6. 线程join()规则：主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现），当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程的操作。
```
Thread B = new Thread(()->{
 // 此处对共享变量 var 修改
 var = 66;
});
// 例如此处对共享变量修改，
// 则这个修改结果对线程 B 可见
// 主线程启动子线程
B.start();
B.join()
// 子线程所有对共享变量的修改
// 在主线程调用 B.join() 之后皆可见
// 此例中，var==66
```
7. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。
8. 对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。
---
# 互斥锁
原子性：一个或者多个操作在CPU执行的过程中不被中断的特性；
> 原子性问题的源头：线程切换
> 
> 单CPU情况
> 如若能禁用线程切换，即可解决原子性问题
> 操作系统做线程切换依赖CPU中断，所以禁止CPU中断就能禁止线程切换
> 
> 多核场景
> 同一时刻，有可能有两个线程同时执行，此时禁止CPU中断，只能保证CPU上的线程连续执行，并不能保证同一时刻只有一个线程执行，当两个线程同时写long型变量高32位时，就会出现并发问题

互斥：同一时刻只有一个线程执行

## synchronized
修饰方法（静态和非静态）、代码块。
当synchronized修饰静态方法时，锁定的是当前类的Class对象。
当修饰非静态方法时，锁定的是当前实力对象this。
```java
class X {
 // 修饰非静态方法
 synchronized void foo() {
 // 临界区
 }
 // 修饰静态方法
 synchronized static void bar() {
 // 临界区
 }
 // 修饰代码块
 Object obj = new Object();
 void baz() {
 synchronized(obj) {
 // 临界区
 }
 }
}
```
> 主要分析出程序执行的先后，锁只能保证加锁的区间线程安全，无法保证非区间内的事情
> 保证多线程环境下共享变量的一致性，最好使用共享标志（用锁保证共享变量）
> 方法中声明标志参数，用锁保证安全，其他线程读取数据时先观察标志是否完成

---
一把锁保护多个资源会导致所有的操作都串行，影响性能
细粒度锁：用不同的锁对受保护资源进行精细化管理，提升性能
```java
// 线程不安全，无法保证线程之前的顺序
class Account {
 private int balance;
 // 转账
 synchronized void transfer(
 Account target, int amt){
 if (this.balance > amt) {
 this.balance -= amt;
 target.balance += amt;
 }
 }
}

// 通过传入对象锁，保证多线程直接有序读取共享变量
class Account {
   private Object lock;
   private int balance;
   private Account();
   // 创建 Account 时传入同一个 lock 对象
   public Account(Object lock) {
      this.lock = lock;
   }
   // 转账
   void transfer(Account target, int amt){
      // 此处检查所有对象共享的锁
      synchronized(lock) {
         if (this.balance > amt) {
            this.balance -= amt;
            target.balance += amt;
         }
      }
   }
}

// 将对象锁替换为类
class Account {
   private int balance;
// 转账
void transfer(Account target, int amt){
   synchronized(Account.class) {
      if (this.balance > amt) {
         this.balance -= amt;
         target.balance += amt;
      }
   }
}
}
```
> 原子性的本质：多个资源间有一致性要求，操作的中间状态对外不可见。
---
死锁：一组相互竞争资源的线程因相互等待，导致永久阻塞的现象。
出现死锁的四个条件：
1. 互斥：共享资源X和Y只能被一个线程占用
2. 占有且等待，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X
3. 不可抢占，其他线程不能强行抢占T1占有的资源
4. 循环等待，线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源。
> 对于资源的互斥，无法改变
> 可以改变内容如下
> 占有且等待，将资源变为不可以分割的整体或者一次性申请所有的资源，申请不到也不占有部分资源
> 不可抢占，占用部分资源的线程进一步申请其他资源时，如果申请不到，主动释放它占有的资源
> 循环等待，靠按序申请资源来预防，所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的
>
> 当前部分资源被线程占用后，线程不主动释放，其他线程无法主动获取，循环等待
> 

- 破坏占用且等待条件
```java
class Allocator {
 private List<Object> als = new ArrayList<>();
 // 一次性申请所有资源
 synchronized boolean apply(Object from, Object to){
 if(als.contains(from) || als.contains(to)){
 return false;
 } else {
 als.add(from);
 als.add(to);
 }
 return true;
 }
 // 归还资源
synchronized void free(Object from, Object to){
   als.remove(from);
   als.remove(to);
}
}
class Account {
   // actr 应该为单例
   private Allocator actr;
   private int balance;
   // 转账
   void transfer(Account target, int amt){
      // 一次性申请转出账户和转入账户，直到成功
      while(!actr.apply(this, target));
      try{
         // 锁定转出账户
         synchronized(this){
            // 锁定转入账户
            synchronized(target){
               if (this.balance > amt){
                  this.balance -= amt;
                  target.balance += amt;
               }
            }
         }
      } finally {
         actr.free(this, target);
      }
   }
}

```
- 破坏不可抢占条件
- 破坏循环等待条件
```java
// 对账户进行排序，确保出发传递依赖时，按照确认的顺序进行加锁
class Account {
 private int id;
 private int balance;
 // 转账
 void transfer(Account target, int amt){
 Account left = this;
 Account right = target; 
 if (this.id > target.id) { 
 left = target; 
 right = this; 
 } 
 // 锁定序号小的账户
 synchronized(left){
 // 锁定序号大的账户
 synchronized(right){
 if (this.balance > amt){
 this.balance -= amt;
 target.balance += amt;
 }
 }
 }
 }
}
```
---
一个完整的等待-通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待线程，重新获取互斥锁。

- wait()，notify()，notifyALl()方法操作的等待队列时互斥锁的等待队列
- wait()，notify()，notifyALl()都是在synchronized()内部被调用，在synchronized{}外部调用会抛出IllegalMonitorStateException
![wait()操作工作原理](img/wait()操作工作原理.png)
![notify()操作工作原理图](img/notify()操作工作原理图.png)
> wait() 释放锁在进入等待队列
> notify()只能保证通知时间点，条件是满足，但是线程执行的具体时间点是由CPU分配时间片确认的，可能线程在执行时条件已不满足。

等待-通知机制中，四个需要考虑的要素
1. 互斥锁：this作为互斥锁
2. 线程要求的条件：准出账户和转入账户都没有被分配过。
3. 何时等待：线程要求的条件不满足就等待
4. 何时通知：当线程释放账户时通知

```java
class Allocator {
 private List<Object> als;
 // 一次性申请所有资源
 synchronized void apply(Object from, Object to){
 // 经典写法
 while(als.contains(from) || als.contains(to)){
 try{
 wait();
 }catch(Exception e){
 }
 }
 als.add(from);
 als.add(to);
 }
 // 归还资源
 synchronized void free(Object from, Object to){
    als.remove(from);
    als.remove(to);
    notifyAll();
 }
}
```
- notify()和notifyAll()的区别
  - notify()是随机地通知等待队列中的一个线程
  - notify()会通知等待队列中的所有线程
> 使用notify()可能会导致某些线程永远不会被通知到

> wait和sleep的区别
> wait会释放所有锁而sleep不会释放锁资源
> wait只能在同步方法或者同步代码块中使用，sleep可以在任何地方使用
> wait无需不抓异常，sleep需要
> wait是Object类方法，sleep是Thread方法
> sleep方法需要出入指定时间

---
竞态条件(Race Condition)：程序的执行结果依赖线程执行的顺序
活锁：线程虽然没发生阻塞，但仍然会存在执行不下去的情况
饥饿：线程因无法访问所需资源而无法执行下去的情况

> 阿姆达尔(Amdahl)定律：处理器并行运算之后效率提升的能力
![阿姆达尔(Amdahl)定律](img/阿姆达尔定律.png)
公式中n为CPU核数，p为并行百分比，(1-p)为串行百分比
临界区都是串行的，非临界区都是并行的，用单线程执行临界区的时间/用单线程执行(临界区+非临界区)的时间就是串行百分比

避免锁带来的性能问题
1. 使用无所的算法和数据结构：线程本地存储(Thread Local Storage TLS)、写入时复制(Copy-on-write)、乐观锁等。
2. 减少锁持有的时间：互斥锁的本质是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。如ConcurrentHashMap分段锁，读写锁

- 性能方面度量的指标
  - 吞吐量：指的是单位时间内能处理的请求数量。吞吐量越高，说明性能越好。
  - 延迟：从发出请求到收到响应的时间。延迟越小，说明性能越好。
  - 并发量：能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。
---
管程(Monitor)：管理共享变量以及对共享变量的操作过程

> 并发编程的两大核心问题：
> 互斥：同一时刻只允许一个线程访问共享资源
> 同步：线程之间如何通讯、协作。


![MESA管程模型.png](img/MESA管程模型.png)
> 参照 concurrent.java.test02.queue.BlockedQueue
```
MESA管程特有：有一个编程范式，就是需要在一个while循环里面调用wait()
while(条件不满足) {
  wait();
}
```
> Hasen模型：要求notify()放在代码的最后，线程执行完成后再去唤醒其他线程，可以保证线程完成
```
// T2
执行内容
notify()
结束

// T1
wait()
执行内容
```
> Hoare模型: 线程交替顺序执行，中断当前线程，唤醒另一个线程，另一个线程执行完成后再唤醒原线程，能够保证线程完成
```
// T2
notify()
wait()
执行内容

// T1 
wait()
执行内容
notify()
```
> MESA模型：
```
// T2
notify()
执行内容

// T1
判断条件
  wait()
执行内容
```

- notify()的使用条件
  - 所有等待线程拥有相同的等待条件
  - 所有等待线程被唤醒后，执行相同的操作
  - 只需要唤醒一个线程
---
通用的线程生命周期
- 初始状态：线程已经被创建，但尚未分配CPU执行（编程层面被创建，但是操作系统层面还没创建线程）
- 可运行状态：线程可以分配CPU执行（操作系统层面创建线程）
- 运行状态：线程被分配到CPU
- 休眠状态：运行状态的线程如果调用一个阻塞的API或者等待某个事件，线程的状态就会转换到休眠状态，同时释放CPU使用权，休眠状态的线程永远没有机会获得 CPU 使用权。当等待的事件出现了，线程就会从休眠状态转换到可运行状态。
- 终止状态：线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了。
![通用线程状态转换图.png](img/通用线程状态转换图.png)

Java中线程的六种状态
1. NEW（初始化状态）
2. RUNNABLE（可运行 / 运行状态）
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

- RUNNABLE 与 BLOCKED 的状态转换
  - 只有一种场景会触发这种转换，就是线程等待 synchronized 的隐式锁。
  - synchronized 修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，等待的线程就会从 RUNNABLE 转换到 BLOCKED 状态。而当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。
- RUNNABLE 与 WAITING 的状态转换
  - RUNNABLE 与 WAITING 的状态转换
  - 调用无参数的 Thread.join() 方法。其中的 join() 是一种线程同步方法
    - 例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。
  - 调用 LockSupport.park() 方法
    - 调用 LockSupport.park() 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。
- RUNNABLE 与 TIMED_WAITING 的状态转换
  - 调用带超时参数的 Thread.sleep(long millis) 方法；
  - 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法；
  - 调用带超时参数的 Thread.join(long millis) 方法；
  - 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法；
  - 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法。
- 从 NEW 到 RUNNABLE 状态
  - Thread调用start()方法
- 从 RUNNABLE 到 TERMINATED 状态
  - 线程执行完 run() 方法后，会自动转换到 TERMINATED 状态，当然如果执行 run() 方法的时候异常抛出，也会导致线程终止
    - 主动调用Thread类中的stop()方法（已废弃，不建议使用）或者interrupt()方法
> stop()和interrupt()的区别
> stop()方法会杀死线程，如果线程持有ReentrantLock锁，被 stop() 的线程并不会自动调用 ReentrantLock 的 unlock() 去释放锁，那其他线程就再也没机会获得 ReentrantLock 锁。
> 类似的方法还有 suspend() 和 resume() 方法，这两个方法同样也都不建议使用。
> interrupt() 方法仅仅是通知线程，线程有机会执行一些后续操作，同时也可以无视这个通知，线程收到interrupt通知（InterruptedException）后会清楚中断标志

举例说明线程A被触发interrupt()
- 当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 
  InterruptedException 异常。转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似 wait()、join()、sleep() 这样的方法，从看这些方法的签名，发现都会 
  throws InterruptedException 这个异常。这个异常的触发条件就是：其他线程调用了该线程的 interrupt() 方法。
- 当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发 java.
  nio.channels.ClosedByInterruptException 这个异常。阻塞在 java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 
  的 java.nio.channels.Selector 会立即返回。

---
- 延迟：发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好
- 吞吐量：在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好
> 两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换

提升性能，从度量的角度，主要是降低延迟，提高吞吐量
在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率.

---
I/O密集型计算：I/O操作执行的时间相对于CPU计算来说都非常长
CPU密集型计算：CPU密集型计算大部分场景下都是纯CPU计算

> 对于CPU密集型计算场景，理论上，线程的数量=CPU核数，但在实际工程中，线程的数量一般会设置为 CPU核数+1，这样即使线程因为偶尔的内存页失效或者其他原因导致阻塞时，额外的线程也可顶上，从而保证CPU的利用率。

> 如果CPU 计算和 I/O 操作的耗时是 1:1，那么 2 个线程是最合适的。如果 CPU 计算和 I/O 操作的耗时是 1:2，那多少个线程合适呢？是 3 个线程。

![三线程执行示意图.png](三线程执行示意图.png)
CPU 在 A、B、C 三个线程之间切换，对于线程 A，当 CPU 从 B、C 切换回来时，线程 A 正好执行完 I/O 操作。这样 CPU 和 I/O 设备的利用率都达到了 100%。

- 对于I/O密集型计算场景，最佳的线程数是与程序中CPU计算和I/O操作的耗时比相关
  - 单核CPU： 最佳线程数 = 1 + (I/O耗时 / CPU耗时)
  - 多核CPU： 最佳线程数 = CPU 核数 * [ 1 + (I/O耗时 / CPU耗时)]





 
